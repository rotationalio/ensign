[{"id":0,"href":"/system/configuration/","title":"Configuration","section":"System","content":"Note: This page is for internal Ensign development and will probably not be very useful to Ensign users.\nConfiguration # Ensign services are primarily configured using environment variables and will respect dotenv files in the current working directory. The canonical reference of the configuration for an Ensign service is the config package of that service (described below). This documentation enumerates the most important configuration variables, their default values, and any hints or warnings about how to use them.\nRequired Configuration\nIf a configuration parameter does not have a default value that means it is required and must be specified by the user! If the configuration parameter does have a default value then that environment variable does not have to be set. Ensign # The Ensign node is a replica of the Ensign eventing system. Its environment variables are all prefixed with the ENSIGN_ tag. The primary configuration is as follows:\nEnvVar Type Default Description ENSIGN_MAINTENANCE bool false Sets the node to maintenance mode, which will respond to requests with Unavailable except for status requests. ENSIGN_LOG_LEVEL string info The verbosity of logging, one of trace, debug, info, warn, error, fatal, or panic. ENSIGN_CONSOLE_LOG bool false If true will print human readable logs instead of JSON logs for machine consumption. ENSIGN_BIND_ADDR string :5356 The address and port the Ensign service will listen on. Sentry # Ensign uses Sentry to assist with error monitoring and performance tracing. Configure Ensign to use Sentry as follows:\nEnvVar Type Default Description ENSIGN_SENTRY_DSN string The DSN for the Sentry project. If not set then Sentry is considered disabled. ENSIGN_SENTRY_SERVER_NAME string Optional - a server name to tag Sentry events with. ENSIGN_SENTRY_ENVIRONMENT string The environment to report (e.g. development, staging, production). Required if Sentry is enabled. ENSIGN_SENTRY_RELEASE string {{version}} Specify the release of Ensign for Sentry tracking. By default this will be the package version. ENSIGN_SENTRY_TRACK_PERFORMANCE bool false Enable performance tracing to Sentry with the specified sample rate. ENSIGN_SENTRY_SAMPLE_RATE float64 0.2 The percentage of transactions to trace (0.0 to 1.0). ENSIGN_SENTRY_DEBUG bool false Set Sentry to debug mode for testing. Sentry is considered enabled if a DSN is configured. Performance tracing is only enabled if Sentry is enabled and track performance is set to true. If Sentry is enabled, an environment is required, otherwise the configuration will be invalid.\nGenerally speaking, Ensign should enable Sentry for panic reports but should not enable performance tracing as this slows down the server too much. Note also that the sentry.Config object has a field Repanic that should not be set by the user. This field is used to manage panics in chained interceptors.\nMonitoring # Ensign uses Prometheus for metrics and observability. The Prometheus metrics server is configured as follows:\nEnvVar Type Default Description ENSIGN_MONITORING_ENABLED bool true If true, the Prometheus metrics server is served. ENSIGN_MONITORING_BIND_ADDR string :1205 The address and port the metrics server will listen on. ENSIGN_MONITORING_NODE_ID string Optional - a server name to tag metrics with. Tenant # The Tenant API powers the user front-end for tenant management and configuration. Its environment variables are all prefixed with the TENANT_ tag. The primary configuration is as follows:\nEnvVar Type Default Description TENANT_MAINTENANCE bool false Sets the server to maintenance mode, which will respond to requests with Unavailable except for status requests. TENANT_BIND_ADDR string :8080 The address and port the Tenant service will listen on. TENANT_MODE string release Sets the Gin mode, one of debug, release, or test. TENANT_LOG_LEVEL string info The verbosity of logging, one of trace, debug, info, warn, error, fatal, or panic. TENANT_CONSOLE_LOG bool false If true will print human readable logs instead of JSON logs for machine consumption. TENANT_ALLOW_ORIGINS string http://localhost:3000 A comma separated list of allowed origins for CORS. Set to \u0026ldquo;*\u0026rdquo; to allow all origins. SendGrid # Tenant uses SendGrid to assist with email notifications. Configure Tenant to use SendGrid as follows:\nEnvVar Type Default Description TENANT_SENDGRID_API_KEY string API Key to authenticate to SendGrid with. TENANT_SENDGRID_FROM_EMAIL string ensign@rotational.io The email address in the \u0026ldquo;from\u0026rdquo; field of emails being sent to users. TENANT_SENDGRID_ADMIN_EMAIL string admins@rotational.io The email address to send admin emails to from the server. TENANT_SENDGRID_ENSIGN_LIST_ID string A contact list to add users to if they sign up for notifications. SendGrid is considered enabled if the SendGrid API Key is set. The from and admin email addresses are required if SendGrid is enabled.\nIf the Ensign List ID is configured then Tenant will add the contact requesting private beta access to that list, otherwise it will simply add the contact to \u0026ldquo;all contacts\u0026rdquo;.\nSentry # Tenant uses Sentry to assist with error monitoring and performance tracing. Configure Tenant to use Sentry as follows:\nEnvVar Type Default Description TENANT_SENTRY_DSN string The DSN for the Sentry project. If not set then Sentry is considered disabled. TENANT_SENTRY_SERVER_NAME string Optional - a server name to tag Sentry events with. TENANT_SENTRY_ENVIRONMENT string The environment to report (e.g. development, staging, production). Required if Sentry is enabled. TENANT_SENTRY_RELEASE string {{version}} Specify the release of Ensign for Sentry tracking. By default this will be the package version. TENANT_SENTRY_TRACK_PERFORMANCE bool false Enable performance tracing to Sentry with the specified sample rate. TENANT_SENTRY_SAMPLE_RATE float64 0.2 The percentage of transactions to trace (0.0 to 1.0). TENANT_SENTRY_DEBUG bool false Set Sentry to debug mode for testing. Sentry is considered enabled if a DSN is configured. Performance tracing is only enabled if Sentry is enabled and track performance is set to true. If Sentry is enabled, an environment is required, otherwise the configuration will be invalid.\nNote also that the sentry.Config object has a field Repanic that should not be set by the user. This field is used to manage panics in chained interceptors.\nQuarterdeck # The Quarterdeck API handles authentication and authorization as well as API keys and billing management for the Ensign managed service. Its environment variables are all prefixed with the QUARTERDECK_ tag. The primary configuration is as follows:\nEnvVar Type Default Description QUARTERDECK_MAINTENANCE bool false Sets the server to maintenance mode, which will respond to requests with Unavailable except for status requests. QUARTERDECK_BIND_ADDR string :8088 The address and port the Quarterdeck service will listen on. QUARTERDECK_MODE string release Sets the Gin mode, one of debug, release, or test. QUARTERDECK_LOG_LEVEL string info The verbosity of logging, one of trace, debug, info, warn, error, fatal, or panic. QUARTERDECK_CONSOLE_LOG bool false If true will print human readable logs instead of JSON logs for machine consumption. QUARTERDECK_ALLOW_ORIGINS string http://localhost:3000 A comma separated list of allowed origins for CORS. Set to \u0026ldquo;*\u0026rdquo; to allow all origins. Database # EnvVar Type Default Description QUARTERDECK_DATABASE_URL string sqlite3:////data/db/quarterdeck.db The DSN for the sqlite3 database. QUARTERDECK_DATABASE_READ_ONLy bool false If true only read-only transactions are allowed. Quarterdeck uses a Raft replicated Sqlite3 database for authentication. The URI should have the scheme sqlite3:// and then a path to the database. For a relative path, use sqlite3:///path/to/relative.db and for an absolute path use sqlite3:////path/to/absolute.db.\nTokens # EnvVar Type Default Description QUARTERDECK_TOKEN_KEYS map[string]string The private keys to load into quarterdeck to issue JWT tokens with. QUARTERDECK_TOKEN_AUDIENCE string ensign.rotational.app:443 The audience to add to the JWT keys for verification. QUARTERDECK_TOKEN_ISSUER string https://auth.rotational.app The issuer to add to the JWT keys for verification. To create an environment variable that is a map[string]string use a string in the following form:\nkey1:value1,key2:value2 The token keys should be ULIDs keys (for ordering) and a path value to the key pair to load from disk. Generally speaking there should be two keys - the current key and the most recent previous key, though more keys can be added for verification. Only the most recent key will be used to issue tokens, however. For example, here is a valid key map:\n01GECSDK5WJ7XWASQ0PMH6K41K:/data/keys/01GECSDK5WJ7XWASQ0PMH6K41K.pem,01GECSJGDCDN368D0EENX23C7R:/data/keys/01GECSJGDCDN368D0EENX23C7R.pem Future Feature\nNote that in the future quarterdeck will generate its own keys and will not need them to be set as in the configuration above. Sentry # Quarterdeck uses Sentry to assist with error monitoring and performance tracing. Configure Quarterdeck to use Sentry as follows:\nEnvVar Type Default Description QUARTERDECK_SENTRY_DSN string The DSN for the Sentry project. If not set then Sentry is considered disabled. QUARTERDECK_SENTRY_SERVER_NAME string Optional - a server name to tag Sentry events with. QUARTERDECK_SENTRY_ENVIRONMENT string The environment to report (e.g. development, staging, production). Required if Sentry is enabled. QUARTERDECK_SENTRY_RELEASE string {{version}} Specify the release of Ensign for Sentry tracking. By default this will be the package version. QUARTERDECK_SENTRY_TRACK_PERFORMANCE bool false Enable performance tracing to Sentry with the specified sample rate. QUARTERDECK_SENTRY_SAMPLE_RATE float64 0.2 The percentage of transactions to trace (0.0 to 1.0). QUARTERDECK_SENTRY_DEBUG bool false Set Sentry to debug mode for testing. Sentry is considered enabled if a DSN is configured. Performance tracing is only enabled if Sentry is enabled and track performance is set to true. If Sentry is enabled, an environment is required, otherwise the configuration will be invalid.\nNote also that the sentry.Config object has a field Repanic that should not be set by the user. This field is used to manage panics in chained interceptors.\nBeacon # A React app delivers Beacon, the Ensign UI. Its environment variables are all prefixed with the REACT_APP tag. The primary configuration is as follows:\nGoogle Analytics # The React app uses Google Analytics to monitor website traffic. Configure the React app to use Google Analytics as follows:\nEnvVar Type Default Description REACT_APP_ANALYTICS_ID string Google Analytics tracking ID for the React App. Sentry # The React app uses Sentry to assist with error monitoring and performance tracing. Configure the React app to use Sentry as follows:\nEnvVar Type Default Description REACT_APP_SENTRY_DSN string The DSN for the Sentry project. If not set then Sentry is considered disabled. REACT_APP_SENTRY_ENVIRONMENT string The environment to report (e.g. development, staging, production). Required if Sentry is enabled. Sentry is considered enabled if a DSN is configured. If Sentry is enabled, an environment is strongly suggested, otherwise the NODE_ENV environment will be used.\nDevelopment # Keep up to Date!\nIt is essential that we keep this configuration documentation up to date. The devops team uses it to ensure its services are configured correctly. Any time a configuration is changed ensure this documentation is also updated! TODO: this section will discuss envconfig, how to interpret environment variables from the configuration struct, how to test configuration, and how to add and change configuration variables. This section should also discuss dotenv files, docker compose, and all of the places where configuration can be influenced (e.g. GitHub actions for React builds).\n"},{"id":1,"href":"/getting-started/","title":"Getting Started","section":"Ensign Documentation","content":" Welcome! # Ready to get started with eventing? Let\u0026rsquo;s go!\nWhat is Ensign? # Ensign is a new eventing tool that make it fast, convenient, and fun to create event-driven microservices without needing a big team of devOps or platform engineers. All you need is a free API key to get started.\nGetting Started # The first step is to get an Ensign API key by visiting the sign-up page. Similar to getting a developer API key for Youtube, Twitter or Data.gov, you will need an API key to use Ensign and to follow along with the rest of this Quickstart guide.\nYour key consists of two parts, a ClientID and a ClientSecret. The ClientID uniquely identifies you, and the ClientSecret proves that you have permission to create and access event data.\nAPI Key Component Name Length Characters Example ClientID 32 alphabetic (no digits) DbIxBEtIUgNIClnFMDmvoZeMrLxUTJVa ClientSecret 64 alphanumeric wAfRpXLTiWn7yo7HQzOCwxMvveqiHXoeVJghlSIK2YbMqOMCUiSVRVQOLT0ORrVS Together, the ClientID and ClientSecret uniquely identify you. They enable you to create Ensign topics, publishers, and subscribers, which will be the building blocks of your microservice! Keep in mind that the ClientID and ClientSecret should be kept private and not shared.\nPrerequisites # Ensign\u0026rsquo;s SDK currently supports Golang (Python and Javascript coming soon!). If you haven\u0026rsquo;t already:\ndownload and install Golang according to your operating system set up your GOPATH and workspace Install Ensign # In your command line, type the following to install the ensign API, SDK, and library code for Go:\ngo get -u github.com/rotationalio/ensign/sdks/go@latest Create a Client # After you\u0026rsquo;ve made a new Go project for this example, create a main.go file and add the dependencies you\u0026rsquo;ll need, which will include importing the Ensign API, SDK, and mimetypes.\nNext, create an Ensign client, which is similar to establishing a connection to a database like PostgreSQL or Mongo. To create the client, use the New method and pass in an ensign.Options struct that specifies your Client ID and Client Secret (described in the section above on getting an API key).\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;context\u0026#34; api \u0026#34;github.com/rotationalio/ensign/pkg/api/v1beta1\u0026#34; mimetype \u0026#34;github.com/rotationalio/ensign/pkg/mimetype/v1beta1\u0026#34; ensign \u0026#34;github.com/rotationalio/ensign/sdks/go\u0026#34; ) client, err := ensign.New(\u0026amp;ensign.Options{ ClientID: \u0026#34;DbIxBEtIUgNIClnFMDmvoZeMrLxUTJVa\u0026#34;, ClientSecret: \u0026#34;wAfRpXLTiWn7yo7HQzOCwxMvveqiHXoeVJghlSIK2YbMqOMCUiSVRVQOLT0ORrVS\u0026#34;, }) if err != nil { fmt.Errorf(\u0026#34;could not create client: %s\u0026#34;, err) } Congratulations, you now have an open connection to Ensign!\nCreate a Publisher # The next step is to start publishing data onto your event stream. Start by creating a publisher using the Publish method:\npub, err := client.Publish(context.Background()) if err != nil { fmt.Errorf(\u0026#34;could not create publisher: %s\u0026#34;, err) } Next, we need some data! Generally this is the place where you\u0026rsquo;d connect to your live data source (a database, Twitter feed, weather data, etc). But to keep things simple, we\u0026rsquo;ll just create a single event, which starts with a map.\ndata := make(map[string]string) data[\u0026#34;sender\u0026#34;] = \u0026#34;Twyla\u0026#34; data[\u0026#34;timestamp\u0026#34;] = time.Now().String() data[\u0026#34;message\u0026#34;] = \u0026#34;Let\u0026#39;s get this started!\u0026#34; Next, we will convert our map into an event, which will allow you to specify the mimetype of the message you intend to send (in this case, we\u0026rsquo;ll say it\u0026rsquo;s JSON), and the event type (which will be a generic event for this example). You\u0026rsquo;ll also need to pass in a TopicId, which will be a string. If you aren\u0026rsquo;t sure what TopicId to use, you can quickly log into your Ensign dashboard and look it up. For this example, we\u0026rsquo;ll pretend it\u0026rsquo;s \u0026quot;quality-lemon-time\u0026quot;:\ne := \u0026amp;api.Event{ TopicId: \u0026#34;quality-lemon-time\u0026#34;, Mimetype: mimetype.ApplicationJSON, Type: \u0026amp;api.Type{ Name: \u0026#34;Generic\u0026#34;, Version: 1, }, } Next, we\u0026rsquo;ll marshal our dictionary into the Data attribute of our sample event, and publish it by calling the Publish method on the publisher we created above:\ne.Data, _ = json.Marshal(data) pub.Publish(e) Create a Subscriber # Creating a subscriber is a bit more straightforward:\nsub, err := client.Subscribe(context.Background()) if err != nil { fmt.Errorf(\u0026#34;could not create subscriber: %s\u0026#34;, err) } var events \u0026lt;-chan *api.Event if events, err = sub.Subscribe(); err != nil { panic(\u0026#34;failed to create subscribe stream: \u0026#34; + err.Error()) } for msg := range events { fmt.Println(msg.Data) } Next Steps # You\u0026rsquo;re already well on your way to building your first event-driven microservice with Ensign!\nIf you\u0026rsquo;re ready to see some more advanced examples with code, check out the End-to-end Examples.\nIf you\u0026rsquo;re looking for more on the basics of event-driven systems, check out Eventing 101.\nHappy eventing!\n"},{"id":2,"href":"/examples/","title":"End-to-End Examples","section":"Ensign Documentation","content":" End-to-End Examples # This section of the documentation provides end-to-end examples using Ensign to help get you started!\nEnsign for Application Developers: In this end-to-end example, see how to curate a custom Twitter feed using Ensign. Create a publisher to start emitting tweets to a topic stream in just a few minutes! See how to create one or more asynchronous subscribers that can read off the stream and process the data as needed. "},{"id":3,"href":"/eventing/","title":"Eventing 101","section":"Ensign Documentation","content":" Eventing 101 # Still getting familiar with eventing basics? You\u0026rsquo;ve come to the right place!\nGlossary # Here\u0026rsquo;s a handy list of terms to help get you started:\napi key # \u0026ldquo;API\u0026rdquo; stands for \u0026ldquo;Application Programming Interface\u0026rdquo;, which is a very broad term that refers (super high level) to the ways in which users or other applications can interact with an application.\nSome applications (like Ensign) require permission to interact with, such as a password, token, or key.\nYou can get a free Ensign API key by visiting rotational.io/ensign. Your key will consist of two parts, a ClientID and a ClientSecret. The ClientID uniquely identifies you, and the ClientSecret proves that you have permission to create and access event data. You will need to pass both of these in to create an Ensign client connection.\nasynchronous # An asynchronous microservice is one in which requests to a service and the subsequent responses are decoupled and can occur independently of each other.\nThis differs from the synchronous pattern, in which a client request (e.g. a query) is blocked from moving forward until a server response is received. Synchronous microservices can result in cascading failures and compounding latencies in applications.\nAsynchronous microservices can make it a lot easier for teams to develop and deploy components independently.\nAsynchronous microservices require an intermediary service usually known as a broker to hold messages emitted by a publisher that are awaiting retrieval from subscribers.\nbroker # An event broker is an intermediary service inside an asynchronous eventing system that stores events sent by publishers until they are received by all subscribers.\nBrokers are also in charge of things like keeping events in the correct order, remembering which subscribers are listening to a topic stream, recording the last message each subscriber retrieved, etc.\nIn Ensign, brokers can save events permanently even after they have been retrieved (to support \u0026ldquo;time travel\u0026rdquo; — the ability to retroactively scan through an event stream to support analytics and machine learning).\nclient # In order to write or read data from an underlying data system (like a database or event stream), you need a client to connect to the data system and interact with it as needed (such as reading and writing data). This connection often looks something like conn = DBConnection(credentials), and after creating the conn variable, subsequent lines of code can leverage it to perform the kinds of data interactions you wish to make.\nTo establish a client in Ensign you need an API key.\nimport ( ensign \u0026#34;github.com/rotationalio/ensign/sdks/go\u0026#34; ) client, err := ensign.New(\u0026amp;ensign.Options{ ClientID: \u0026#34;FMDmvoZeMrLxUTJVaDbIxBEtIUgNICln\u0026#34;, ClientSecret: \u0026#34;oeVJghlSIK2YbMqOMCUiSVRVQOLT0ORrVSwAfRpXLTiWn7yo7HQzOCwxMvveqiHX\u0026#34;, }) event # In an event-driven or microservice architecture, an event is the atomic element of data.\nAn event might look something like a dictionary, which is then wrapped in an object or struct that provides some schema information to help Ensign know how to serialize and deserialize your data.\norder := make(map[string]string) order[\u0026#34;item\u0026#34;] = \u0026#34;large mushroom pizza\u0026#34; order[\u0026#34;customer_id\u0026#34;] = \u0026#34;984445\u0026#34; order[\u0026#34;customer_name\u0026#34;] = \u0026#34;Enson J. Otterton\u0026#34; order[\u0026#34;timestamp\u0026#34;] = time.Now().String() evt := \u0026amp;api.Event{ TopicId: \u0026#34;order-feed\u0026#34;, Mimetype: mimetype.ApplicationJSON, Type: \u0026amp;api.Type{ Name: \u0026#34;Generic\u0026#34;, Version: 1, }, } evt.Data, _ = json.Marshal(order) latency # Latency can refer to both application-level communication lag (e.g. the time it takes for one part of the code to finish running before moving on to the next part) or to network communication lag (e.g. the time it takes for two remote servers on two different continents to send a single message back and forth).\nLess latency is better, generally speaking.\nIn a microservices context, we can reduce application latency by using asynchronous communications and parallelizing functions so they run faster. Network latency can be reduced by creating more efficient communications between servers (e.g. using more scalable consensus algorithms).\nmicroservice # A microservice is a computer application composed of a collection of lightweight services, each of which is responsible for some discrete task.\nMicroservices can be coordinated to communicate via events.\nmime type # A MIME (Multipurpose Internet Mail Extensions) type is a label that identifies a type of data, such as CSV, HTML, JSON, or protocol buffer.\nMIME types allow an application to understand how to handle incoming and outgoing data.\norganization # An Ensign organization is a collection of users who are working under the same Ensign tenant.\npublisher # In an event-driven microservice, a publisher is responsible for emitting events to a topic stream.\nIn Ensign, you can create a publisher once you have established a client:\npub, err := client.Publish(...) real-time # This is a tricky one because real-time can be used to mean different things. In some cases, \u0026ldquo;real-time\u0026rdquo; is used as a synonym for synchronous (i.e. the opposite of asynchronous). However, the term is also used to mean \u0026ldquo;very fast\u0026rdquo; or \u0026ldquo;low latency\u0026rdquo;.\nsdk # SDK stands for \u0026ldquo;Software Development Kit\u0026rdquo;. Software applications designed for a technical/developer audience frequently are considerate enough to provide user-facing SDKs in a few languages (e.g. Golang, Python, JavaScript). These SDKs give users a convenient way to interact with the application using a programming language with which they are familiar.\nEnsign currently offers two SDKs: the Golang SDK and a Watermill API-compatible SDK.\nstream # An event stream is a flow composed of many, many individual pieces of data called events.\nsubscriber # In an event-driven context, a subscriber is a downstream component that is listening for events published by a publisher onto a topic.\ntenant # A tenant is a user, group of users, team or company who share computing and/or storage resources.\ntopic # In event-driven microservices, a topic is a rough approximation of a traditional relational database table. In a relational DB, a table is a collection of related data fields arrayed as columns and rows. In an eventing context, a topic is a sequence of individual events populated with the same fields (aka schema).\nResources # Prototyping Event-Driven Applications The Eventing Platform Landscape Gently Down the Stream Watermill "},{"id":4,"href":"/sdk/","title":"SDKs","section":"Ensign Documentation","content":" SDKs # This is the primary section for Ensign users.\n"},{"id":5,"href":"/examples/developers/","title":"Ensign for Application Developers","section":"End-to-End Examples","content":" Ensign for Application Developers # Hi there! This tutorial is targeted towards Golang application developers. If you are interested in or currently writing event-driven applications in Go you are in the right place! In this code-driven tutorial we will use the Ensign Golang SDK to publish curated tweets to an event stream and retrieve them in real time.\nIf you came here for the code the full example is available here.\nPrerequisites # To follow along with this tutorial you\u0026rsquo;ll need to:\nGenerate an API key to access Ensign Set up a developer account with Twitter (it\u0026rsquo;s free) Add a phone number to your Twitter developer account Set up your GOPATH and workspace Project Setup # The first thing we need to do is setup an environment to run our code. Let\u0026rsquo;s create a blank module with a suitable name for our project:\n$ mkdir tweets $ go mod init github.com/rotationalio/ensign-examples/go/tweets Next we\u0026rsquo;ll need to install the Go SDK client and its dependencies from the GitHub repo. In this tutorial we also use the go-twitter client to interact with the twitter API (although you can also create the requests yourself)!\n$ go get -u github.com/rotationalio/ensign/sdks/go@latest $ go get -u github.com/g8rswimmer/go-twitter/v2@latest Our project needs a publisher to write events to Ensign and a subscriber to read those events (asynchronously). In a real application these would most likely be independent microservices that run in different execution contexts (e.g. containers in a k8s cluster or even across different regions). Let\u0026rsquo;s create separate packages for the two command line applications as well as a shared package for our event schemas.\n$ mkdir publish $ mkdir subscribe $ mkdir schemas Sourcing Tweets # In event-driven systems, events are the main unit of data. In production applications events might be sourced from user actions, IoT devices, webhooks, or act as control signals between microservices.\nFor this example our data source is curated tweets from twitter. Create a file called main.go in the publish directory and add the following code to it.\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;context\u0026#34; twitter \u0026#34;github.com/g8rswimmer/go-twitter/v2\u0026#34; ) type authorize struct { Token string } func (a authorize) Add(req *http.Request) { req.Header.Add(\u0026#34;Authorization\u0026#34;, fmt.Sprintf(\u0026#34;Bearer %s\u0026#34;, a.Token)) } func main() { var ( err error token string ) if token = os.Getenv(\u0026#34;TWITTER_API_BEARER_TOKEN\u0026#34;); token == \u0026#34;\u0026#34; { panic(\u0026#34;TWITTER_API_BEARER_TOKEN environment variable is required\u0026#34;) } query := flag.String(\u0026#34;query\u0026#34;, \u0026#34;distributed systems\u0026#34;, \u0026#34;Twitter search query\u0026#34;) flag.Parse() tweets := \u0026amp;twitter.Client{ Authorizer: authorize{ Token: *token, }, Client: http.DefaultClient, Host: \u0026#34;https://api.twitter.com\u0026#34;, } ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second) defer cancel() var rep *tweets.TweetRecentSearchResponse if rep, err = client.TweetRecentSearch(ctx, *query, twitter.TweetRecentSearchOpts{}); err != nil { panic(err) } for _, errs := range rep.Raw.Errors { fmt.Printf(\u0026#34;Error: %s\\n\u0026#34;, errs.Detail) } for _, tweet := range rep.Raw.Tweets { fmt.Printf(\u0026#34;%s: %s\\n\u0026#34;, tweet.AuthorID, tweet.Text) } } This is a simple command line application that will retrieve a single page of search results from twitter and print them out. Feel free to build the program and run it with any search query to make sure it works!\n$ export TWITTER_API_BEARER_TOKEN=# Your Twitter API bearer token goes here $ cd publish $ go build -o publish main.go $ ./publish --query \u0026#34;distributed systems\u0026#34; Creating a Publisher # Now that we have a data source, the next step is to create an Ensign client using the Client ID and Client Secret pair you received when generating your API key.\nimport ( ... twitter \u0026#34;github.com/g8rswimmer/go-twitter/v2\u0026#34; ensign \u0026#34;github.com/rotationalio/ensign/sdks/go\u0026#34; ) func main() { var ( err error token string ) if token = os.Getenv(\u0026#34;TWITTER_API_BEARER_TOKEN\u0026#34;); token == \u0026#34;\u0026#34; { panic(\u0026#34;TWITTER_API_BEARER_TOKEN environment variable is required\u0026#34;) } query := flag.String(\u0026#34;query\u0026#34;, \u0026#34;distributed systems\u0026#34;, \u0026#34;Twitter search query\u0026#34;) flag.Parse() // ENSIGN_CLIENT_ID and ENSIGN_CLIENT_SECRET environment variables must be set var client *ensign.Client if client, err = ensign.New(\u0026amp;ensign.Options{}); err != nil { panic(\u0026#34;failed to create Ensign client: \u0026#34; + err.Error()) } ... In the Go SDK, creating a Publisher interface from the client is straightforward.\nvar pub ensign.Publisher if pub, err = client.Publish(context.Background()); err != nil { panic(\u0026#34;failed to create publisher from Ensign client: \u0026#34; + err.Error()) } Publishing Events # In Ensign, events include a lot more than the data itself. As we can see from the protocol buffer, events are self-descriptive and are quite flexible.\ntype Event struct { state protoimpl.MessageState sizeCache protoimpl.SizeCache unknownFields protoimpl.UnknownFields Id string `protobuf:\u0026#34;bytes,1,opt,name=id,proto3\u0026#34; json:\u0026#34;id,omitempty\u0026#34;` TopicId string `protobuf:\u0026#34;bytes,2,opt,name=topic_id,json=topicId,proto3\u0026#34; json:\u0026#34;topic_id,omitempty\u0026#34;` Mimetype v1beta1.MIME `protobuf:\u0026#34;varint,3,opt,name=mimetype,proto3,enum=mimetype.v1beta1.MIME\u0026#34; json:\u0026#34;mimetype,omitempty\u0026#34;` Type *Type `protobuf:\u0026#34;bytes,4,opt,name=type,proto3\u0026#34; json:\u0026#34;type,omitempty\u0026#34;` Key []byte `protobuf:\u0026#34;bytes,5,opt,name=key,proto3\u0026#34; json:\u0026#34;key,omitempty\u0026#34;` Data []byte `protobuf:\u0026#34;bytes,6,opt,name=data,proto3\u0026#34; json:\u0026#34;data,omitempty\u0026#34;` Encryption *Encryption `protobuf:\u0026#34;bytes,7,opt,name=encryption,proto3\u0026#34; json:\u0026#34;encryption,omitempty\u0026#34;` Compression *Compression `protobuf:\u0026#34;bytes,8,opt,name=compression,proto3\u0026#34; json:\u0026#34;compression,omitempty\u0026#34;` Geography *Region `protobuf:\u0026#34;bytes,9,opt,name=geography,proto3\u0026#34; json:\u0026#34;geography,omitempty\u0026#34;` Publisher *Publisher `protobuf:\u0026#34;bytes,10,opt,name=publisher,proto3\u0026#34; json:\u0026#34;publisher,omitempty\u0026#34;` UserDefinedId string `protobuf:\u0026#34;bytes,11,opt,name=user_defined_id,json=userDefinedId,proto3\u0026#34; json:\u0026#34;user_defined_id,omitempty\u0026#34;` Created *timestamppb.Timestamp `protobuf:\u0026#34;bytes,14,opt,name=created,proto3\u0026#34; json:\u0026#34;created,omitempty\u0026#34;` Committed *timestamppb.Timestamp `protobuf:\u0026#34;bytes,15,opt,name=committed,proto3\u0026#34; json:\u0026#34;committed,omitempty\u0026#34;` } For this tutorial we are mostly concerned with the following fields.\nTopicId: Events are organized into topics and events in a topic usually follow a similar schema Mimetype: In Ensign all event data is generic \u0026ldquo;blob\u0026rdquo; data to allow for heterogenous event streams. The mimetype allows subcribers to deserialize data back into an understandable format. Type: Events in Ensign are tagged with schema type and versioning info to allow publishers and subscribers to lookup schemas in a shared registry. This is important because certain serialization methods (e.g. protobuf, parquet) require explicit schemas for deserialization and schema-less methods (e.g. JSON) can be enhanced with versioning. In this example we can get away with structured JSON. In production worfklows we would most likely want to store the definition in a schema registry but for now let\u0026rsquo;s add it to tweets.go in the schemas directory so both our producer and subscriber can access it.\npackage schemas type Tweet struct { Author string `json:\u0026#34;author\u0026#34;` Text string `json:\u0026#34;text\u0026#34;` CreatedAt string `json:\u0026#34;created_at\u0026#34;` } Now that we know how to serialize JSON, in the tweet loop instead of printing to the console let\u0026rsquo;s go ahead and publish some events.\nfor _, tweet := range rep.Raw.Tweets { e := \u0026amp;api.Event{ TopicId: \u0026#34;tweets\u0026#34;, Mimetype: mimetype.ApplicationJSON, Type: \u0026amp;api.Type{ Name: \u0026#34;tweet\u0026#34;, Version: 1, }, } tweetObj := \u0026amp;schemas.Tweet{ Author: tweet.AuthorID, Text: tweet.Text, CreatedAt: tweet.CreatedAt, } if e.Data, err = json.Marshal(tweetObj); err != nil { panic(\u0026#34;could not marshal tweet to JSON: \u0026#34; + err.Error()) } // Publish the event to Ensign pub.Publish(e) // Check for errors if err = pub.Err(); err != nil { panic(\u0026#34;failed to publish event(s): \u0026#34; + err.Error()) } } If your IDE did not resolve the imports for you, you will need to specify them manually:\nimport ( ... api \u0026#34;github.com/rotationalio/ensign/pkg/api/v1beta1\u0026#34; mimetype \u0026#34;github.com/rotationalio/ensign/pkg/mimetype/v1beta1\u0026#34; ... ) Note that pub.Publish(e) does not return an immediate error, it\u0026rsquo;s an asynchronous operation so if we want to check for errors we have to do so after the fact. This means that we can\u0026rsquo;t be sure which event actually triggered the error.\nFinally, to make our publisher feel like a real service, we can add an outer loop with a ticker so that the program periodically pulls the most recent tweets our search query of choice. Another useful improvement might be to utilize the SinceID on the twitter search options so that we aren\u0026rsquo;t producing duplicate tweets!\nticker := time.NewTicker(10 * time.Second) sinceID := \u0026#34;\u0026#34; for { ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second) defer cancel() select { case \u0026lt;-ctx.Done(): return case \u0026lt;-ticker.C: fmt.Println(\u0026#34;searching for tweets...\u0026#34;) opts := twitter.TweetRecentSearchOpts{ SortOrder: twitter.TweetSearchSortOrderRecency, SinceID: sinceID, } var rep *twitter.TweetRecentSearchResponse if rep, err = tweets.TweetRecentSearch(ctx, *query, opts); err != nil { panic(err) } for _, errs := range rep.Raw.Errors { fmt.Printf(\u0026#34;Error: %s\\n\u0026#34;, errs.Detail) } for _, tweet := range rep.Raw.Tweets { e := \u0026amp;api.Event{ TopicId: \u0026#34;tweets\u0026#34;, Mimetype: mimetype.ApplicationJSON, Type: \u0026amp;api.Type{ Name: \u0026#34;Generic\u0026#34;, Version: 1, }, } if e.Data, err = json.Marshal(tweet); err != nil { panic(\u0026#34;could not marshal tweet to JSON: \u0026#34; + err.Error()) } pub.Publish(e) if err = pub.Err(); err != nil { panic(\u0026#34;failed to publish event(s): \u0026#34; + err.Error()) } fmt.Printf(\u0026#34;published tweet with ID: %s\\n\u0026#34;, tweet.ID) } if len(rep.Raw.Tweets) \u0026gt; 0 { sinceID = rep.Raw.Tweets[0].ID } } } At this point our publisher will be able to request some new tweets from Twitter every 10 seconds and publish them as events to the tweets topic. Go ahead and try it out!\n$ export ENSIGN_CLIENT_ID=# Your Ensign Client ID goes here $ export ENSIGN_CLIENT_SECRET=# Your Ensign Client Secret goes here $ go build -o publish main.go $ ./publish --query \u0026#34;otters\u0026#34; Note: Here the Ensign Client ID and Client Secret are retrieved from environment variables but it\u0026rsquo;s also possible to specify them in code\nCreating a subscriber # Similarly to the Publisher, a Subscriber interface can be created from an Ensign client. Once created, the Subscriber allows us to read events directly from a Go channel. Create a main.go in the subscribe directory and add the following code to it.\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/rotationalio/ensign-examples/go/tweets/schemas\u0026#34; api \u0026#34;github.com/rotationalio/ensign/pkg/api/v1beta1\u0026#34; ensign \u0026#34;github.com/rotationalio/ensign/sdks/go\u0026#34; ) func main() { var ( err error client *ensign.Client ) // ENSIGN_CLIENT_ID and ENSIGN_CLIENT_SECRET environment variables must be set if client, err = ensign.New(\u0026amp;ensign.Options{}); err != nil { panic(\u0026#34;failed to create Ensign client: \u0026#34; + err.Error()) } // Create a subscriber from the client var sub ensign.Subscriber if sub, err = client.Subscribe(context.Background()); err != nil { panic(\u0026#34;failed to create subscriber from client: \u0026#34; + err.Error()) } defer sub.Close() // Create the event stream as a channel var events \u0026lt;-chan *api.Event if events, err = sub.Subscribe(); err != nil { panic(\u0026#34;failed to create subscribe stream: \u0026#34; + err.Error()) } // Events are processed as they show up on the channel for event := range events { tweet := \u0026amp;schemas.Tweet{} if err = json.Unmarshal(event.Data, tweet); err != nil { panic(\u0026#34;failed to unmarshal event: \u0026#34; + err.Error()) } fmt.Printf(\u0026#34;received tweet %s\\n\u0026#34;, tweet.ID) fmt.Println(tweet.Text) fmt.Println() } } At this point you should be able to build and the run the subscriber in a second command window to retrieve tweet events in real time!\n$ export ENSIGN_CLIENT_ID=# Your Ensign Client ID $ export ENSIGN_CLIENT_SECRET=# Your Ensign Client Secret $ cd subscribe $ go build -o subscribe main.go $ ./subscribe What Next? # Hopefully this gets you on the right track and inspires some ideas for event-driven applications. If this example were to become a real application, here are some things we might consider.\nEvent Schemas # Remember that an Ensign event encodes a lot of metadata. When dealing with more strutured or versioned serialization formats such as protobuf, we definitely want to consider adding some logic to the subscriber to lookup the event schema in the schema registry or a local cache with the event.Type field.\nAdditional Topic Streams # With Ensign it\u0026rsquo;s easy to scale up by adding new topics. We might want to have different topics for error observability (e.g. if the Twitter API changes or schemas unexpectedly change), metrics capturing, or different types of Twitter queries.\nDownstream Processing # Once we have an event stream, what do we do with it? A traditional approach is to capture data into a database for persistence and to make it easy to materialize data views for application users. This is certainly possible with Ensign. However, Ensign also offers persistence of event streams, which makes it possible to perform historical queries on the streams themselves.\n"},{"id":6,"href":"/system/","title":"System","section":"Ensign Documentation","content":" System # This section of the documentation describes the Ensign system.\n"}]